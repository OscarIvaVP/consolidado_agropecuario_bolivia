{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1SnL9oHFYvG5EVLnfTUCozxbrzGaSqmQd","authorship_tag":"ABX9TyMuBlkinqCXUx7URTuU+D6J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import required libraries\n","import pandas as pd\n","\n","# Load the Excel file\n","file_path = '/content/drive/MyDrive/BID/ULTIMOS/bolivia/input/datos_bolivia_compilados.xlsx'\n","xls = pd.ExcelFile(file_path)\n","\n","# Load the data from both sheets\n","ha_df = pd.read_excel(xls, sheet_name='ha')\n","ton_df = pd.read_excel(xls, sheet_name='ton')\n","\n","# Reshaping the data to the desired format using pandas' melt function\n","\n","# Transform the \"ha\" dataframe\n","ha_df_melted = ha_df.melt(id_vars=['Departamento', 'Cultivo'],\n","                          var_name='Año',\n","                          value_name='ha')\n","\n","# Transform the \"ton\" dataframe\n","ton_df_melted = ton_df.melt(id_vars=['Departamento', 'Cultivo'],\n","                            var_name='Año',\n","                            value_name='ton')\n","\n","# Replace non-numeric values in the 'ha' and 'ton' columns with 0\n","\n","# For ha_df_melted\n","ha_df_melted['ha'] = pd.to_numeric(ha_df_melted['ha'], errors='coerce').fillna(0)\n","\n","# For ton_df_melted\n","ton_df_melted['ton'] = pd.to_numeric(ton_df_melted['ton'], errors='coerce').fillna(0)\n","\n","# Define the translation dictionary\n","translations = {\n","    \"Palma Africana (Fruta Fresca)\": \"Oil palm\",\n","    \"Maíz\": \"Corn\",\n","    \"Arroz con cáscara\": \"Rice\",\n","    \"Soya\": \"Soy\",\n","    \"Plátano (Fruta Fresca)\": \"Plantain\",\n","    'Caña de Azúcar': 'Sugarcane',\n","    'Caña De Azúcar Para Otros Usos (Tallo Fresco)': 'Sugarcane',\n","    \"Yuca (Raíz Fresca)\": \"Yuca\",\n","    \"Cacao (Almendra Seca)\": \"Cocoa\",\n","    \"MARAÑÓN\": \"Cashew\",\n","    \"Café (Grano Oro)\": \"Coffee\",\n","    'Sorgo en grano': 'Sorghum',\n","    'Trigo': 'Wheat',\n","    'Girasol': 'Sunflower',\n","    'Papa': 'Potato',\n","    'Frijol': 'Bean',\n","    'Alfalfa': 'Alfalfa',\n","    'Cebada': 'Barley',\n","    'Maíz Duro Seco (Grano Seco)': 'Corn',\n","    'Maíz Duro Choclo (En Choclo)': 'Corn',\n","    'Maíz Suave Choclo (En Choclo)': 'Corn',\n","    'Maíz Suave Seco (Grano Seco)': 'Corn',\n","    'Frijol/poroto': 'Bean',\n","    'Fréjol Tierno (En Vaina)': 'Bean',\n","    'Naranja (Fruta Fresca)': 'Orange',\n","    'Orito (Fruta Fresca)': 'Orito',\n","    'Maíz en grano': 'Corn',\n","    'Alfalfa': 'Alfalfa'\n","}\n","\n","# Apply the translation to the 'Cultivo' column in both datasets\n","ha_df_melted['Cultivo'] = ha_df_melted['Cultivo'].replace(translations)\n","ton_df_melted['Cultivo'] = ton_df_melted['Cultivo'].replace(translations)\n","\n","# Filter data for the specific departments\n","departments_to_include = [\"Beni\", \"Cochabamba\", \"Chuquisaca\", \"La Paz\", \"Pando\", \"Santa Cruz\"]\n","ha_filtered = ha_df_melted[ha_df_melted['Departamento'].isin(departments_to_include)]\n","ton_filtered = ton_df_melted[ton_df_melted['Departamento'].isin(departments_to_include)]\n","\n","# Filter the data for the year 2023\n","ha_2023 = ha_filtered[ha_filtered['Año'] == 2023]\n","ton_2023 = ton_filtered[ton_filtered['Año'] == 2023]\n","\n","# Identify the top 10 crops by total hectares in 2023\n","top_10_crops_ha = ha_2023.groupby('Cultivo')['ha'].sum().nlargest(10).index\n","\n","# Filter the datasets to include only the top 10 crops\n","ha_top_10 = ha_2023[ha_2023['Cultivo'].isin(top_10_crops_ha)]\n","ton_top_10 = ton_2023[ton_2023['Cultivo'].isin(top_10_crops_ha)]\n","\n","# Merge the two datasets on Departamento, Cultivo, and Año to get both ha and ton for 2023\n","merged_top_10_2023 = pd.merge(ha_top_10, ton_top_10, on=['Departamento', 'Cultivo', 'Año'], suffixes=('_ha', '_ton'))\n","\n","# Group by 'Cultivo' and calculate the total hectares and tons for each crop\n","summary_top_10_2023 = merged_top_10_2023.groupby('Cultivo').agg({'ha': 'sum', 'ton': 'sum'}).reset_index()\n","\n","# Prepare the dataframe in the desired structure for Departments\n","# Create a list of unique departments for 2023 filtered data\n","departments_2023 = merged_top_10_2023['Departamento'].unique()\n","structured_data = []\n","\n","# Iterate over each department\n","for dept in departments_2023:\n","    # Filter data for the current department\n","    dept_data = merged_top_10_2023[merged_top_10_2023['Departamento'] == dept]\n","\n","    # Create a dictionary for hectares (ha) row\n","    ha_row = {'Departamento': dept, 'Indicador': 'ha'}\n","    # Create a dictionary for tonnes (ton) row\n","    ton_row = {'Departamento': dept, 'Indicador': 'ton'}\n","\n","    # Populate the hectares and tonnes values for each crop in the top 10 list\n","    for _, row in dept_data.iterrows():\n","        ha_row[row['Cultivo']] = row['ha']\n","        ton_row[row['Cultivo']] = row['ton']\n","\n","    # Append the rows to the list\n","    structured_data.append(ha_row)\n","    structured_data.append(ton_row)\n","\n","# Create a dataframe from the list of dictionaries\n","structured_df = pd.DataFrame(structured_data)\n","\n","# Prepare the dataframe in the desired structure based on Cultivo and Indicator, with columns for each Department\n","# Create a list of unique crops in the top 10 list for 2023\n","crops_2023 = merged_top_10_2023['Cultivo'].unique()\n","structured_data_cultivo = []\n","\n","# Iterate over each crop\n","for crop in crops_2023:\n","    # Filter data for the current crop\n","    crop_data = merged_top_10_2023[merged_top_10_2023['Cultivo'] == crop]\n","\n","    # Create a dictionary for hectares (ha) row\n","    ha_row = {'Cultivo': crop, 'Indicador': 'ha'}\n","    # Create a dictionary for tonnes (ton) row\n","    ton_row = {'Cultivo': crop, 'Indicador': 'ton'}\n","\n","    # Populate the hectares and tonnes values for each department in the dataset\n","    for _, row in crop_data.iterrows():\n","        ha_row[row['Departamento']] = row['ha']\n","        ton_row[row['Departamento']] = row['ton']\n","\n","    # Append the rows to the list\n","    structured_data_cultivo.append(ha_row)\n","    structured_data_cultivo.append(ton_row)\n","\n","# Create a dataframe from the list of dictionaries\n","structured_df_cultivo = pd.DataFrame(structured_data_cultivo)\n","\n","# Define the path to save the new Excel file\n","output_file_path = '/content/drive/MyDrive/BID/ULTIMOS/bolivia/output/tablas_cultivo_bolivia.xlsx'\n","\n","# Create a Pandas Excel writer using XlsxWriter as the engine\n","with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n","    # Write each dataframe to a different worksheet\n","    summary_top_10_2023.to_excel(writer, sheet_name='Resumen_Top_10', index=False)\n","    structured_df.to_excel(writer, sheet_name='Deptos_Ha_Ton', index=False)\n","    structured_df_cultivo.to_excel(writer, sheet_name='Cultivos_Ha_Ton', index=False)\n","\n","# Provide the path to the user for downloading the file\n","output_file_path\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XH-7p5tJRwB8","executionInfo":{"status":"ok","timestamp":1731631541614,"user_tz":-60,"elapsed":4089,"user":{"displayName":"Trabajo Científico","userId":"01741028045546139754"}},"outputId":"58d689dd-f403-4d59-fb04-63f3c4077714"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/BID/ULTIMOS/bolivia/output/tablas_cultivo_bolivia.xlsx'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["!pip install xlsxwriter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qROyHyZQOKj6","executionInfo":{"status":"ok","timestamp":1731631535364,"user_tz":-60,"elapsed":3832,"user":{"displayName":"Trabajo Científico","userId":"01741028045546139754"}},"outputId":"e4c330a6-6edc-47fb-8e09-ab373dd9a90b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xlsxwriter\n","  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m153.6/159.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.2.0\n"]}]}]}